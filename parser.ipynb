{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d69dfe6-19de-412f-815e-0504ddc8454d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:51:54.334761Z",
     "iopub.status.busy": "2024-01-30T07:51:54.334066Z",
     "iopub.status.idle": "2024-01-30T07:51:55.645051Z",
     "shell.execute_reply": "2024-01-30T07:51:55.644307Z",
     "shell.execute_reply.started": "2024-01-30T07:51:54.334731Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderConfig\n",
    "\n",
    "image_size = [1280, 960]\n",
    "max_length = 768\n",
    "\n",
    "# update image_size of the encoder\n",
    "# during pre-training, a larger image size was used\n",
    "config = VisionEncoderDecoderConfig.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "config.encoder.image_size = image_size # (height, width)\n",
    "# update max_length of the decoder (for generation)\n",
    "config.decoder.max_length = max_length\n",
    "# TODO we should actually update max_position_embeddings and interpolate the pre-trained ones:\n",
    "# https://github.com/clovaai/donut/blob/0acc65a85d140852b8d9928565f0f6b2d98dc088/donut/model.py#L602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38bdb8fd-945b-43ac-ade5-ec8a0697d2c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:51:55.646769Z",
     "iopub.status.busy": "2024-01-30T07:51:55.646232Z",
     "iopub.status.idle": "2024-01-30T07:52:02.989011Z",
     "shell.execute_reply": "2024-01-30T07:52:02.988359Z",
     "shell.execute_reply.started": "2024-01-30T07:51:55.646747Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e66a164-4d64-41ac-8071-a413bb2f99a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:02.990588Z",
     "iopub.status.busy": "2024-01-30T07:52:02.989915Z",
     "iopub.status.idle": "2024-01-30T07:52:03.002486Z",
     "shell.execute_reply": "2024-01-30T07:52:03.001894Z",
     "shell.execute_reply.started": "2024-01-30T07:52:02.990576Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from typing import Any, List, Tuple\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "added_tokens = []\n",
    "\n",
    "class DocDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str,\n",
    "        max_length: int,\n",
    "        split: str = \"train\",\n",
    "        ignore_id: int = -100,\n",
    "        task_start_token: str = \"\",\n",
    "        prompt_end_token: str = None,\n",
    "        sort_json_key: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.split = split\n",
    "        self.ignore_id = ignore_id\n",
    "        self.task_start_token = task_start_token\n",
    "        self.prompt_end_token = prompt_end_token if prompt_end_token else task_start_token\n",
    "        self.sort_json_key = sort_json_key\n",
    "\n",
    "        self.img_root = f\"{dataset_path}/images/\"\n",
    "        self.parse_root = f\"{dataset_path}/parse_seq_data/\"\n",
    "        \n",
    "        self.image_files = [f for f in Path(self.img_root).iterdir() if f.is_file() and not f.name.startswith('.')]\n",
    "        self.parse_files = [f for f in Path(self.parse_root).iterdir() if f.is_file() and not f.name.startswith('.')]\n",
    "\n",
    "        self.gt_token_sequences = []\n",
    "\n",
    "        for sample in self.parse_files:\n",
    "            if sample.is_file() and sample.suffix == \".json\":\n",
    "                with open(sample, 'r') as file:\n",
    "                    gt_json = json.load(file)\n",
    "            \n",
    "            self.gt_token_sequences.append([\n",
    "                self.json2token(\n",
    "                    gt_json,\n",
    "                    update_special_tokens_for_json_key=self.split == \"train\",\n",
    "                    sort_json_key=self.sort_json_key\n",
    "                )\n",
    "                + processor.tokenizer.eos_token\n",
    "            ])\n",
    "\n",
    "        self.add_tokens([self.task_start_token, self.prompt_end_token])\n",
    "        self.prompt_end_token_id = processor.tokenizer.convert_tokens_to_ids(self.prompt_end_token)\n",
    "\n",
    "    def json2token(self, obj: Any, update_special_tokens_for_json_key: bool = True, sort_json_key: bool = True):\n",
    "        if type(obj) == dict:\n",
    "            if len(obj) == 1 and \"text_sequence\" in obj:\n",
    "                return obj[\"text_sequence\"]\n",
    "            else:\n",
    "                output = \"\"\n",
    "                if sort_json_key:\n",
    "                    keys = sorted(obj.keys(), reverse=True)\n",
    "                else:\n",
    "                    keys = obj.keys()\n",
    "                for k in keys:\n",
    "                    if update_special_tokens_for_json_key:\n",
    "                        self.add_tokens([fr\"<{k}>\", fr\"<{k}/>\"])\n",
    "                    output += (\n",
    "                        fr\"<{k}>\"\n",
    "                        + self.json2token(obj[k], update_special_tokens_for_json_key, sort_json_key)\n",
    "                        + fr\"<{k}/>\"\n",
    "                    )\n",
    "                return output\n",
    "        elif type(obj) == list:\n",
    "            return r\"\".join(\n",
    "                [self.json2token(item, update_special_tokens_for_json_key, sort_json_key) for item in obj]\n",
    "            )\n",
    "        else:\n",
    "            obj = str(obj)\n",
    "            if f\"<{obj}/>\" in added_tokens:\n",
    "                obj = f\"<{obj}/>\"  # for categorical special tokens\n",
    "            return obj\n",
    "        \n",
    "    def add_tokens(self, list_of_tokens: List[str]):\n",
    "        \"\"\"\n",
    "        Add special tokens to tokenizer and resize the token embeddings of the decoder\n",
    "        \"\"\"\n",
    "        newly_added_num = processor.tokenizer.add_tokens(list_of_tokens)\n",
    "        if newly_added_num > 0:\n",
    "            model.decoder.resize_token_embeddings(len(processor.tokenizer))\n",
    "            added_tokens.extend(list_of_tokens)\n",
    "            \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.parse_files)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        image_path = self.image_files[idx]\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        pixel_values = processor(image, random_padding=self.split == \"train\", return_tensors=\"pt\").pixel_values\n",
    "        pixel_values = pixel_values.squeeze()\n",
    "\n",
    "        target_sequence = random.choice(self.gt_token_sequences[idx])\n",
    "\n",
    "        input_ids = processor.tokenizer(\n",
    "            target_sequence,\n",
    "            add_special_tokens=False,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )[\"input_ids\"].squeeze(0)\n",
    "\n",
    "        labels = input_ids.clone()\n",
    "\n",
    "        labels[labels == processor.tokenizer.pad_token_id] = self.ignore_id\n",
    "\n",
    "        return pixel_values, labels, target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608ff2b4-ef74-4879-a9b4-a51bf7eabe56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:03.003748Z",
     "iopub.status.busy": "2024-01-30T07:52:03.003192Z",
     "iopub.status.idle": "2024-01-30T07:52:05.583769Z",
     "shell.execute_reply": "2024-01-30T07:52:05.583223Z",
     "shell.execute_reply.started": "2024-01-30T07:52:03.003725Z"
    }
   },
   "outputs": [],
   "source": [
    "processor.image_processor.size = image_size[::-1] # should be (width, height)\n",
    "processor.image_processor.do_align_long_axis = False\n",
    "\n",
    "train_dataset = DocDataset(dataset_path=\"dataset/train\", max_length=max_length, split=\"train\", task_start_token=\"<s_parse>\", prompt_end_token=\"\",\n",
    "                             sort_json_key=False)\n",
    "val_dataset = DocDataset(dataset_path=\"dataset/val\", max_length=max_length, split=\"validation\", task_start_token=\"<s_parse>\", prompt_end_token=\"\",\n",
    "                             sort_json_key=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eecd4fd-de94-4c06-9e75-5f413d2db5dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:05.585906Z",
     "iopub.status.busy": "2024-01-30T07:52:05.585225Z",
     "iopub.status.idle": "2024-01-30T07:52:05.591236Z",
     "shell.execute_reply": "2024-01-30T07:52:05.590773Z",
     "shell.execute_reply.started": "2024-01-30T07:52:05.585882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(added_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d151a6-4c5f-4b16-9d73-26c99c98f647",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:05.592581Z",
     "iopub.status.busy": "2024-01-30T07:52:05.591898Z",
     "iopub.status.idle": "2024-01-30T07:52:05.595685Z",
     "shell.execute_reply": "2024-01-30T07:52:05.595046Z",
     "shell.execute_reply.started": "2024-01-30T07:52:05.592560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<license_num>', '<license_num/>', '<name>', '<name/>', '<dob>', '<dob/>', '<s_parse>', '<s_parse>']\n"
     ]
    }
   ],
   "source": [
    "print(added_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3daf1b34-38c5-4663-9c7d-b20ea939eb84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:05.596709Z",
     "iopub.status.busy": "2024-01-30T07:52:05.596329Z",
     "iopub.status.idle": "2024-01-30T07:52:05.608777Z",
     "shell.execute_reply": "2024-01-30T07:52:05.608264Z",
     "shell.execute_reply.started": "2024-01-30T07:52:05.596688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of tokens: 57522\n",
      "Number of tokens after adding special tokens: 57532\n"
     ]
    }
   ],
   "source": [
    "print(\"Original number of tokens:\", processor.tokenizer.vocab_size)\n",
    "print(\"Number of tokens after adding special tokens:\", len(processor.tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc8b75c9-c143-4a76-94d5-11c262be93de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:05.610110Z",
     "iopub.status.busy": "2024-01-30T07:52:05.609623Z",
     "iopub.status.idle": "2024-01-30T07:52:05.614254Z",
     "shell.execute_reply": "2024-01-30T07:52:05.613782Z",
     "shell.execute_reply.started": "2024-01-30T07:52:05.610060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<name/>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode([57528])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39759dd9-62f2-4151-b187-b9ec588223d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:05.615491Z",
     "iopub.status.busy": "2024-01-30T07:52:05.614878Z",
     "iopub.status.idle": "2024-01-30T07:52:05.702401Z",
     "shell.execute_reply": "2024-01-30T07:52:05.701830Z",
     "shell.execute_reply.started": "2024-01-30T07:52:05.615470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1280, 960])\n",
      "torch.Size([768])\n",
      "<license_num>01-08-00244454<license_num/><name>ANIL TAMANG<name/><dob>16-07-1980<dob/></s>\n"
     ]
    }
   ],
   "source": [
    "pixel_values, labels, target_sequence = train_dataset[0]\n",
    "print(pixel_values.shape)\n",
    "print(labels.shape)\n",
    "print(target_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5c0b7de-6bb4-4c74-a10c-c08bcc98d288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:05.703679Z",
     "iopub.status.busy": "2024-01-30T07:52:05.703196Z",
     "iopub.status.idle": "2024-01-30T07:52:05.707089Z",
     "shell.execute_reply": "2024-01-30T07:52:05.706301Z",
     "shell.execute_reply.started": "2024-01-30T07:52:05.703651Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids(['<s_parse>'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7824dadf-7be7-42c8-8edb-28a6474844fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:05.708192Z",
     "iopub.status.busy": "2024-01-30T07:52:05.707732Z",
     "iopub.status.idle": "2024-01-30T07:52:05.712548Z",
     "shell.execute_reply": "2024-01-30T07:52:05.711859Z",
     "shell.execute_reply.started": "2024-01-30T07:52:05.708166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57531"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.decoder_start_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e486d5eb-f5cf-408b-be6c-f539e9df1b35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:05.713753Z",
     "iopub.status.busy": "2024-01-30T07:52:05.713192Z",
     "iopub.status.idle": "2024-01-30T07:52:05.717221Z",
     "shell.execute_reply": "2024-01-30T07:52:05.716761Z",
     "shell.execute_reply.started": "2024-01-30T07:52:05.713731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad token ID: <pad>\n",
      "Decoder start token ID: <s_parse>\n"
     ]
    }
   ],
   "source": [
    "print(\"Pad token ID:\", processor.decode([model.config.pad_token_id]))\n",
    "print(\"Decoder start token ID:\", processor.decode([model.config.decoder_start_token_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e078472-70d2-48a1-97b3-7682c48e506f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:05.718292Z",
     "iopub.status.busy": "2024-01-30T07:52:05.717800Z",
     "iopub.status.idle": "2024-01-30T07:52:05.720878Z",
     "shell.execute_reply": "2024-01-30T07:52:05.720273Z",
     "shell.execute_reply.started": "2024-01-30T07:52:05.718272Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dfadd4b-7646-4a3c-ac4c-79edf9691886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:05.723227Z",
     "iopub.status.busy": "2024-01-30T07:52:05.722793Z",
     "iopub.status.idle": "2024-01-30T07:52:05.726747Z",
     "shell.execute_reply": "2024-01-30T07:52:05.725985Z",
     "shell.execute_reply.started": "2024-01-30T07:52:05.723206Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e6f8d71-af43-4f63-939a-da0260a65384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:05.727873Z",
     "iopub.status.busy": "2024-01-30T07:52:05.727360Z",
     "iopub.status.idle": "2024-01-30T07:52:06.200575Z",
     "shell.execute_reply": "2024-01-30T07:52:06.199877Z",
     "shell.execute_reply.started": "2024-01-30T07:52:05.727852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1280, 960])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "pixel_values, labels, target_sequences = batch\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5662e1e-3412-40ca-a656-dfc707837c43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:06.201701Z",
     "iopub.status.busy": "2024-01-30T07:52:06.201479Z",
     "iopub.status.idle": "2024-01-30T07:52:06.207527Z",
     "shell.execute_reply": "2024-01-30T07:52:06.207017Z",
     "shell.execute_reply.started": "2024-01-30T07:52:06.201674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<license_num>\n",
      "03\n",
      "-0\n",
      "6-0\n",
      "03\n",
      "542\n",
      "34\n",
      "<license_num/>\n",
      "<name>\n",
      "K\n",
      "IRAN\n",
      "L\n",
      "AMA\n",
      "<name/>\n",
      "<dob>\n",
      "10\n",
      "-11\n",
      "-\n",
      "1993\n",
      "<dob/>\n",
      "</s>\n",
      "-100\n",
      "-100\n",
      "-100\n",
      "-100\n",
      "-100\n",
      "-100\n",
      "-100\n",
      "-100\n",
      "-100\n"
     ]
    }
   ],
   "source": [
    "for id in labels.squeeze().tolist()[:30]:\n",
    "  if id != -100:\n",
    "    print(processor.decode([id]))\n",
    "  else:\n",
    "    print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59d7dff8-7f8a-4517-9cb0-255c0a429c8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:06.208320Z",
     "iopub.status.busy": "2024-01-30T07:52:06.208113Z",
     "iopub.status.idle": "2024-01-30T07:52:06.211909Z",
     "shell.execute_reply": "2024-01-30T07:52:06.211162Z",
     "shell.execute_reply.started": "2024-01-30T07:52:06.208284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c1f30fd-4296-436b-8de0-e74bf05c37c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:06.213172Z",
     "iopub.status.busy": "2024-01-30T07:52:06.212622Z",
     "iopub.status.idle": "2024-01-30T07:52:06.618114Z",
     "shell.execute_reply": "2024-01-30T07:52:06.617090Z",
     "shell.execute_reply.started": "2024-01-30T07:52:06.213150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1280, 960])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_dataloader))\n",
    "pixel_values, labels, target_sequences = batch\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdf99094-5118-437e-a632-427d15a45ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:06.620517Z",
     "iopub.status.busy": "2024-01-30T07:52:06.619616Z",
     "iopub.status.idle": "2024-01-30T07:52:06.625864Z",
     "shell.execute_reply": "2024-01-30T07:52:06.624795Z",
     "shell.execute_reply.started": "2024-01-30T07:52:06.620480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/></s>\n"
     ]
    }
   ],
   "source": [
    "print(target_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b1cd621-b94e-4391-9af7-0944986bbfea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:06.627209Z",
     "iopub.status.busy": "2024-01-30T07:52:06.626784Z",
     "iopub.status.idle": "2024-01-30T07:52:09.685088Z",
     "shell.execute_reply": "2024-01-30T07:52:09.684058Z",
     "shell.execute_reply.started": "2024-01-30T07:52:06.627176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q pytorch-lightning wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f0d13ac-ede7-4e2a-af52-d7d2cf5b0c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:09.687265Z",
     "iopub.status.busy": "2024-01-30T07:52:09.686400Z",
     "iopub.status.idle": "2024-01-30T07:52:10.910254Z",
     "shell.execute_reply": "2024-01-30T07:52:10.909700Z",
     "shell.execute_reply.started": "2024-01-30T07:52:09.687224Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from nltk import edit_distance\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "\n",
    "class DonutModelPLModule(pl.LightningModule):\n",
    "    def __init__(self, config, processor, model):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pixel_values, labels, _ = batch\n",
    "        \n",
    "        outputs = self.model(pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx, dataset_idx=0):\n",
    "        pixel_values, labels, answers = batch\n",
    "        batch_size = pixel_values.shape[0]\n",
    "        # we feed the prompt to the model\n",
    "        decoder_input_ids = torch.full((batch_size, 1), self.model.config.decoder_start_token_id, device=self.device)\n",
    "        \n",
    "        outputs = self.model.generate(pixel_values,\n",
    "                                   decoder_input_ids=decoder_input_ids,\n",
    "                                   max_length=max_length,\n",
    "                                   early_stopping=True,\n",
    "                                   pad_token_id=self.processor.tokenizer.pad_token_id,\n",
    "                                   eos_token_id=self.processor.tokenizer.eos_token_id,\n",
    "                                   use_cache=True,\n",
    "                                   num_beams=1,\n",
    "                                   bad_words_ids=[[self.processor.tokenizer.unk_token_id]],\n",
    "                                   return_dict_in_generate=True,)\n",
    "    \n",
    "        predictions = []\n",
    "        for seq in self.processor.tokenizer.batch_decode(outputs.sequences):\n",
    "            seq = seq.replace(self.processor.tokenizer.eos_token, \"\").replace(self.processor.tokenizer.pad_token, \"\")\n",
    "            seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
    "            predictions.append(seq)\n",
    "\n",
    "        scores = []\n",
    "        for seq in self.processor.tokenizer.batch_decode(outputs.sequences):\n",
    "            seq = seq.replace(self.processor.tokenizer.eos_token, \"\").replace(self.processor.tokenizer.pad_token, \"\")\n",
    "            seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
    "            predictions.append(seq)\n",
    "\n",
    "        scores = []\n",
    "        for pred, answer in zip(predictions, answers):\n",
    "            pred = re.sub(r\"(?<=\\>) | (?=\\=)\", \"\", answer, count=1).replace(self.processor.tokenizer.eos_token, \"\")\n",
    "            answer = answer.replace(self.processor.tokenizer.eos_token, \"\")\n",
    "            scores.append(edit_distance(pred, answer) / max(len(pred), len(answer)))\n",
    "\n",
    "            if self.config.get(\"verbose\", False) and len(scores) == 1:\n",
    "                print(f\"Prediction: {pred}\")\n",
    "                print(f\"    Answer: {answer}\")\n",
    "                print(f\" Normed ED: {scores[0]}\")\n",
    "\n",
    "        self.log(\"val_edit_distance\", np.mean(scores))\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # you could also add a learning rate scheduler if you want\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.config.get(\"lr\"))\n",
    "    \n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "634dff5e-292d-4662-ad39-b32b4805d0be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:10.911793Z",
     "iopub.status.busy": "2024-01-30T07:52:10.911005Z",
     "iopub.status.idle": "2024-01-30T07:52:10.937128Z",
     "shell.execute_reply": "2024-01-30T07:52:10.936583Z",
     "shell.execute_reply.started": "2024-01-30T07:52:10.911766Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\"max_epochs\":3,\n",
    "          \"val_check_interval\":1, # how many times we want to validate during an epoch\n",
    "          \"check_val_every_n_epoch\":1,\n",
    "          \"gradient_clip_val\":1.0,\n",
    "          \"num_training_samples_per_epoch\": 6,\n",
    "          \"lr\":3e-5,\n",
    "          \"train_batch_sizes\": [1],\n",
    "          \"val_batch_sizes\": [1],\n",
    "          # \"seed\":2022,\n",
    "          \"num_nodes\": 1,\n",
    "          \"warmup_steps\": 300, # 800/8*30/10, 10%\n",
    "          \"result_path\": \"./result\",\n",
    "          \"verbose\": True,\n",
    "          }\n",
    "\n",
    "model_module = DonutModelPLModule(config, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8df36f7b-004c-4140-9731-555d3de482a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:52:10.938384Z",
     "iopub.status.busy": "2024-01-30T07:52:10.937832Z",
     "iopub.status.idle": "2024-01-30T07:53:33.040166Z",
     "shell.execute_reply": "2024-01-30T07:53:33.039555Z",
     "shell.execute_reply.started": "2024-01-30T07:52:10.938360Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/lightning_fabric/connector.py:558: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                      | Params\n",
      "----------------------------------------------------\n",
      "0 | model | VisionEncoderDecoderModel | 201 M \n",
      "----------------------------------------------------\n",
      "201 M     Trainable params\n",
      "0         Non-trainable params\n",
      "201 M     Total params\n",
      "807.437   Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf87ee772bc94a6587fc0408f1cfb91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e7421e0bf244c69ed5191b4fafd4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/generation/configuration_utils.py:433: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b68173dd2d4521998b28994f4b93a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cd97bf8aaf490f922742c27279e336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3441e633e234b0c957f9e5c1784db75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b413f78e98451f9bbd805db4c7bf1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cb547a90124a4c9db170fd99d892ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d782d481c9f46c2978e7a1f4ef12d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b3b93d7ab245c299efc9889ed4c520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6242e213214ef6af4d6bdad62ba236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a4a400b66d45688e0badcd6b28f275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcae32e25774f56a965ecb23ef04b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c13bc9816714008b25f2d8224ce49ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22457c4a03cf454c91a1ab8b87a8adc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29926c00d02d4bd8a3ddf1b59beb1d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b782d79cd9453bb66c173921b663a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc99d6af9ac43fb91d17a16cf4ddcfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81759f5d4ec6488783f7041bf4326bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81616f822f0346d58c0dee0211ab994c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      "    Answer: <license_num>01-06-00037702<license_num/><name>PRAJIN GHIMIRE<name/><dob>25-06-1992<dob/>\n",
      " Normed ED: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_edit_distance\", patience=3, verbose=False, mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        max_epochs=config.get(\"max_epochs\"),\n",
    "        val_check_interval=config.get(\"val_check_interval\"),\n",
    "        check_val_every_n_epoch=config.get(\"check_val_every_n_epoch\"),\n",
    "        gradient_clip_val=config.get(\"gradient_clip_val\"),\n",
    "        precision=16, # we'll use mixed precision\n",
    "        num_sanity_val_steps=0,\n",
    "        enable_checkpointing=True\n",
    ")\n",
    "\n",
    "trainer.fit(model_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aa345e-796a-4a2d-b7cf-3513544bee56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
